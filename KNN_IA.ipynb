{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0VSa_E5_YXVR",
        "outputId": "cb1e8408-4730-4ede-8807-b193f80ac6a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------\n",
            "Dados dos Pacientes - TREINAMENTO - Dimensão  (768, 9)\n",
            "--------------------------------------------------------\n",
            "[[  6.    148.     72.    ...   0.627  50.      1.   ]\n",
            " [  1.     85.     66.    ...   0.351  31.      0.   ]\n",
            " [  8.    183.     64.    ...   0.672  32.      1.   ]\n",
            " ...\n",
            " [  5.    121.     72.    ...   0.245  30.      0.   ]\n",
            " [  1.    126.     60.    ...   0.349  47.      1.   ]\n",
            " [  1.     93.     70.    ...   0.315  23.      0.   ]]\n",
            "---------------------------------\n",
            "Atributos de Entrada\n",
            "---------------------------------\n",
            "[50. 31. 32. 21. 33. 30. 26. 29. 53. 54. 30. 34. 57. 59. 51. 32. 31. 31.\n",
            " 33. 32. 27. 50. 41. 29. 51. 41. 43. 22. 57. 38. 60. 28. 22. 28. 45. 33.\n",
            " 35. 46. 27. 56. 26. 37. 48. 54. 40. 25. 29. 22. 31. 24. 22. 26. 30. 58.\n",
            " 42. 21. 41. 31. 44. 22. 21. 39. 36. 24. 42. 32. 38. 54. 25. 27. 28. 26.\n",
            " 42. 23. 22. 22. 41. 27. 26. 24. 22. 22. 36. 22. 37. 27. 45. 26. 43. 24.\n",
            " 21. 34. 42. 60. 21. 40. 24. 22. 23. 31. 33. 22. 21. 24. 27. 21. 27. 37.\n",
            " 25. 24. 24. 46. 23. 25. 39. 61. 38. 25. 22. 21. 25. 24. 23. 69. 23. 26.\n",
            " 30. 23. 40. 62. 33. 33. 30. 39. 26. 31. 21. 22. 29. 28. 55. 38. 22. 42.\n",
            " 23. 21. 41. 34. 65. 22. 24. 37. 42. 23. 43. 36. 21. 23. 22. 47. 36. 45.\n",
            " 27. 21. 32. 41. 22. 34. 29. 29. 36. 29. 25. 23. 33. 36. 42. 26. 47. 37.\n",
            " 32. 23. 21. 27. 40. 41. 60. 33. 31. 25. 21. 40. 36. 40. 42. 29. 21. 23.\n",
            " 26. 29. 21. 28. 32. 27. 55. 27. 57. 52. 21. 41. 25. 24. 60. 24. 36. 38.\n",
            " 25. 32. 32. 41. 21. 66. 37. 61. 26. 22. 26. 24. 31. 24. 22. 46. 22. 29.\n",
            " 23. 26. 51. 23. 32. 27. 21. 22. 22. 33. 29. 49. 41. 23. 34. 23. 42. 27.\n",
            " 24. 25. 44. 21. 30. 25. 24. 51. 34. 27. 24. 63. 35. 43. 25. 24. 21. 28.\n",
            " 38. 21. 40. 21. 52. 25. 29. 23. 57. 22. 28. 39. 37. 47. 52. 51. 34. 29.\n",
            " 26. 33. 21. 25. 31. 24. 65. 28. 29. 24. 46. 58. 30. 25. 35. 28. 37. 29.\n",
            " 47. 21. 25. 30. 41. 22. 27. 25. 43. 26. 30. 29. 28. 59. 31. 25. 36. 43.\n",
            " 21. 24. 30. 37. 23. 37. 46. 25. 41. 44. 22. 26. 44. 44. 33. 41. 22. 36.\n",
            " 22. 33. 57. 49. 22. 23. 26. 37. 29. 30. 46. 24. 21. 49. 28. 44. 48. 29.\n",
            " 29. 63. 65. 67. 30. 30. 29. 21. 22. 45. 25. 21. 21. 25. 28. 58. 22. 22.\n",
            " 32. 35. 24. 22. 21. 25. 25. 24. 35. 45. 58. 28. 42. 27. 21. 37. 31. 25.\n",
            " 39. 22. 25. 25. 31. 55. 35. 38. 41. 26. 46. 25. 39. 28. 28. 25. 22. 21.\n",
            " 21. 22. 22. 37. 27. 28. 26. 21. 21. 21. 36. 31. 25. 38. 26. 43. 23. 38.\n",
            " 22. 29. 36. 29. 41. 28. 21. 31. 41. 22. 24. 33. 30. 25. 28. 26. 22. 26.\n",
            " 23. 23. 25. 72. 24. 38. 62. 24. 51. 81. 48. 26. 39. 37. 34. 21. 22. 25.\n",
            " 38. 27. 28. 22. 22. 50. 24. 59. 29. 31. 39. 63. 35. 29. 28. 23. 31. 24.\n",
            " 21. 58. 28. 67. 24. 42. 33. 45. 22. 66. 30. 25. 55. 39. 21. 28. 41. 41.\n",
            " 40. 38. 35. 21. 21. 64. 46. 21. 58. 22. 24. 28. 53. 51. 41. 60. 25. 26.\n",
            " 26. 45. 24. 21. 21. 24. 22. 31. 22. 24. 29. 31. 24. 23. 46. 67. 23. 32.\n",
            " 43. 27. 56. 25. 29. 37. 53. 28. 50. 37. 21. 25. 66. 23. 28. 37. 30. 58.\n",
            " 42. 35. 54. 28. 24. 32. 27. 22. 21. 46. 37. 33. 39. 21. 22. 22. 23. 25.\n",
            " 35. 21. 36. 62. 21. 27. 62. 42. 52. 22. 41. 29. 52. 25. 45. 24. 44. 25.\n",
            " 34. 22. 46. 21. 38. 26. 24. 28. 30. 54. 36. 21. 22. 25. 27. 23. 24. 36.\n",
            " 40. 26. 50. 27. 30. 23. 50. 24. 28. 28. 45. 21. 21. 29. 21. 21. 45. 21.\n",
            " 34. 24. 23. 22. 31. 38. 48. 23. 32. 28. 27. 24. 50. 31. 27. 30. 33. 22.\n",
            " 42. 23. 23. 27. 28. 27. 22. 25. 22. 41. 51. 27. 54. 22. 43. 40. 40. 24.\n",
            " 70. 40. 43. 45. 49. 21. 47. 22. 68. 31. 53. 25. 25. 23. 22. 26. 22. 27.\n",
            " 69. 25. 22. 29. 23. 46. 34. 44. 23. 43. 25. 43. 31. 22. 28. 26. 26. 49.\n",
            " 52. 41. 27. 28. 30. 22. 45. 23. 24. 40. 38. 21. 32. 34. 31. 56. 24. 52.\n",
            " 34. 21. 42. 42. 45. 38. 25. 22. 22. 22. 34. 22. 24. 22. 53. 28. 21. 42.\n",
            " 21. 42. 48. 26. 22. 45. 39. 46. 27. 32. 36. 50. 22. 28. 25. 26. 45. 37.\n",
            " 39. 52. 26. 66. 22. 43. 33. 63. 27. 30. 47. 23.]\n",
            "----------------------------\n",
            "Classificação Supervisionada\n",
            "----------------------------\n",
            "[1. 0. 1. 0. 1. 0. 1. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1.\n",
            " 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0.\n",
            " 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0.\n",
            " 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0.\n",
            " 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0.\n",
            " 1. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0.\n",
            " 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0.\n",
            " 1. 1. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1.\n",
            " 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0.\n",
            " 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0.\n",
            " 1. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1.\n",
            " 0. 0. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0. 0.\n",
            " 1. 0. 1. 0. 0. 1. 0. 1. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0.\n",
            " 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1.\n",
            " 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0.\n",
            " 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 1. 1. 0. 1. 0. 1. 0. 1. 0.\n",
            " 1. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0.\n",
            " 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1.\n",
            " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
            " 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.\n",
            " 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
            " 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0.\n",
            " 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 1.\n",
            " 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0.\n",
            " 0. 0. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1.\n",
            " 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1.\n",
            " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1.\n",
            " 0. 0. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0.]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "# Carregando dados do arquivo CSV\n",
        "url = 'https://raw.githubusercontent.com/matheusmt12/KNN-IA/main/diabetes.csv'\n",
        "base_Treinamento = pd.read_csv(url,sep=',', encoding = 'latin1').values\n",
        "print(\"--------------------------------------------------------\")\n",
        "print(\"Dados dos Pacientes - TREINAMENTO - Dimensão \",base_Treinamento.shape)\n",
        "print(\"--------------------------------------------------------\")\n",
        "print(base_Treinamento)\n",
        "print(\"---------------------------------\")\n",
        "\n",
        "# Extração dos Atributos a serem utilizadas pela rede\n",
        "print(\"Atributos de Entrada\")\n",
        "print(\"---------------------------------\")\n",
        "print(base_Treinamento[:, 7])\n",
        "\n",
        "print(\"----------------------------\")\n",
        "print(\"Classificação Supervisionada\")\n",
        "print(\"----------------------------\")\n",
        "print(base_Treinamento[:, 8])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np \n",
        "from sklearn import preprocessing\n",
        "\n",
        "# Binarizador de rótulo\n",
        "processo = preprocessing.MinMaxScaler()\n",
        "\n",
        "Gravidez = processo.fit_transform(np.array(base_Treinamento[:, 0]).reshape(-1,1))\n",
        "Glicose = processo.fit_transform(np.array(base_Treinamento[:, 1]).reshape(-1,1))\n",
        "PressaoArterial = processo.fit_transform(np.array(base_Treinamento[:, 2]).reshape(-1,1))\n",
        "EspessuraPele = processo.fit_transform(np.array(base_Treinamento[:, 3]).reshape(-1,1))\n",
        "Insulina = processo.fit_transform(np.array(base_Treinamento[:, 4]).reshape(-1,1))\n",
        "BMI = processo.fit_transform(np.array(base_Treinamento[:, 5]).reshape(-1,1))\n",
        "DiabetePedigree =processo.fit_transform(np.array(base_Treinamento[:, 6]).reshape(-1,1))\n",
        "Idade = processo.fit_transform(np.array(base_Treinamento[:, 7]).reshape(-1,1))\n",
        "\n",
        "\n",
        "classes = base_Treinamento[:, 8]\n",
        "\n",
        "#Concatenação de Atributos (Colunas) \n",
        "atributos_norm = np.column_stack((Gravidez,Glicose,PressaoArterial,EspessuraPele,Insulina,BMI,DiabetePedigree,Idade))\n",
        "print(\"--------------------------------\")\n",
        "print(\"Atributos de Entrada - Numéricos\")\n",
        "print(\"--------------------------------\")\n",
        "print(atributos_norm)\n",
        "\n",
        "print(\"----------------------------------------\")\n",
        "print(\"Classificação Supervisionada - Numéricos\")\n",
        "print(\"----------------------------------------\")\n",
        "diagnostico_norm = np.hstack((classes))\n",
        "print(diagnostico_norm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pl9vPWfQdFLY",
        "outputId": "71b89b14-7ef0-4f3c-edf9-d2913d5ab927"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------\n",
            "Atributos de Entrada - Numéricos\n",
            "--------------------------------\n",
            "[[0.35294118 0.74371859 0.59016393 ... 0.50074516 0.23441503 0.48333333]\n",
            " [0.05882353 0.42713568 0.54098361 ... 0.39642325 0.11656704 0.16666667]\n",
            " [0.47058824 0.91959799 0.52459016 ... 0.34724292 0.25362938 0.18333333]\n",
            " ...\n",
            " [0.29411765 0.6080402  0.59016393 ... 0.390462   0.07130658 0.15      ]\n",
            " [0.05882353 0.63316583 0.49180328 ... 0.4485842  0.11571307 0.43333333]\n",
            " [0.05882353 0.46733668 0.57377049 ... 0.45305514 0.10119556 0.03333333]]\n",
            "----------------------------------------\n",
            "Classificação Supervisionada - Numéricos\n",
            "----------------------------------------\n",
            "[1. 0. 1. 0. 1. 0. 1. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1.\n",
            " 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0.\n",
            " 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0.\n",
            " 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0.\n",
            " 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0.\n",
            " 1. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0.\n",
            " 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0.\n",
            " 1. 1. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1.\n",
            " 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0.\n",
            " 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0.\n",
            " 1. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1.\n",
            " 0. 0. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0. 0.\n",
            " 1. 0. 1. 0. 0. 1. 0. 1. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0.\n",
            " 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1.\n",
            " 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0.\n",
            " 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 1. 1. 0. 1. 0. 1. 0. 1. 0.\n",
            " 1. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0.\n",
            " 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1.\n",
            " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
            " 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.\n",
            " 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
            " 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0.\n",
            " 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 1.\n",
            " 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0.\n",
            " 0. 0. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1.\n",
            " 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1.\n",
            " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1.\n",
            " 0. 0. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "# Treinamento do Knn a partir dos atributos de entrada e classificações com K=3\n",
        "modelo = KNeighborsClassifier(n_neighbors=1)\n",
        "modelo.fit(atributos_norm, diagnostico_norm)\n",
        "\n",
        "\n",
        "# Acurácia do modelo, que é : 1 - (predições erradas / total de predições)\n",
        "# Acurácia do modelo: indica uma performance geral do modelo. \n",
        "# Dentre todas as classificações, quantas o modelo classificou corretamente;\n",
        "# (VP+VN)/N\n",
        "print('Acurácia: %.3f' % modelo.score(atributos_norm, diagnostico_norm))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V7_WCLrTgre0",
        "outputId": "87b2d13f-f3da-4685-df27-23c780c1e3e7"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acurácia: 1.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "teste = [[17,87,66,25,70,25.5,0.555,32]]\n",
        "print('Teste', modelo.predict(teste))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zf-RL46PhTFv",
        "outputId": "d813b9e2-65ab-4ba9-acda-56f99cac9fea"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Teste [1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# Carregando dados do arquivo CSV\n",
        "url = 'https://raw.githubusercontent.com/matheusmt12/KNN-IA/main/diabetes%20testes.csv.txt'\n",
        "base_Testes = pd.read_csv(url,sep=',', encoding = 'latin1').values\n",
        "print(\"----------------------------\")\n",
        "print(\"Dados dos Pacientes - TESTES\")\n",
        "print(\"----------------------------\")\n",
        "print(base_Testes)\n",
        "print(\"---------------------------------\")\n",
        "\n",
        "# Extração dos Atributos a serem utilizadas pela rede\n",
        "print(\"Atributos de Entrada\")\n",
        "print(\"---------------------------------\")\n",
        "print(base_Testes[:, 0:9])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8f_qreophtQw",
        "outputId": "37d3b389-470b-487e-a952-235312ecf059"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------\n",
            "Dados dos Pacientes - TESTES\n",
            "----------------------------\n",
            "[[6.000e+00 1.480e+02 7.200e+01 3.500e+01 0.000e+00 3.360e+01 6.270e-01\n",
            "  5.000e+01]\n",
            " [1.000e+00 8.500e+01 6.600e+01 2.900e+01 0.000e+00 2.660e+01 3.510e-01\n",
            "  3.100e+01]\n",
            " [8.000e+00 1.830e+02 6.400e+01 0.000e+00 0.000e+00 2.330e+01 6.720e-01\n",
            "  3.200e+01]\n",
            " [1.000e+00 8.900e+01 6.600e+01 2.300e+01 9.400e+01 2.810e+01 1.670e-01\n",
            "  2.100e+01]\n",
            " [0.000e+00 1.370e+02 4.000e+01 3.500e+01 1.680e+02 4.310e+01 2.288e+00\n",
            "  3.300e+01]\n",
            " [5.000e+00 1.160e+02 7.400e+01 0.000e+00 0.000e+00 2.560e+01 2.010e-01\n",
            "  3.000e+01]\n",
            " [3.000e+00 7.800e+01 5.000e+01 3.200e+01 8.800e+01 3.100e+01 2.480e-01\n",
            "  2.600e+01]\n",
            " [1.000e+01 1.150e+02 0.000e+00 0.000e+00 0.000e+00 3.530e+01 1.340e-01\n",
            "  2.900e+01]\n",
            " [2.000e+00 1.970e+02 7.000e+01 4.500e+01 5.430e+02 3.050e+01 1.580e-01\n",
            "  5.300e+01]\n",
            " [8.000e+00 1.250e+02 9.600e+01 0.000e+00 0.000e+00 0.000e+00 2.320e-01\n",
            "  5.400e+01]\n",
            " [4.000e+00 1.100e+02 9.200e+01 0.000e+00 0.000e+00 3.760e+01 1.910e-01\n",
            "  3.000e+01]\n",
            " [1.000e+01 1.680e+02 7.400e+01 0.000e+00 0.000e+00 3.800e+01 5.370e-01\n",
            "  3.400e+01]\n",
            " [1.000e+01 1.390e+02 8.000e+01 0.000e+00 0.000e+00 2.710e+01 1.441e+00\n",
            "  5.700e+01]\n",
            " [1.000e+00 1.890e+02 6.000e+01 2.300e+01 8.460e+02 3.010e+01 3.980e-01\n",
            "  5.900e+01]\n",
            " [5.000e+00 1.660e+02 7.200e+01 1.900e+01 1.750e+02 2.580e+01 5.870e-01\n",
            "  5.100e+01]\n",
            " [7.000e+00 1.000e+02 0.000e+00 0.000e+00 0.000e+00 3.000e+01 4.840e-01\n",
            "  3.200e+01]\n",
            " [0.000e+00 1.180e+02 8.400e+01 4.700e+01 2.300e+02 4.580e+01 5.510e-01\n",
            "  3.100e+01]\n",
            " [7.000e+00 1.070e+02 7.400e+01 0.000e+00 0.000e+00 2.960e+01 2.540e-01\n",
            "  3.100e+01]\n",
            " [1.000e+00 1.030e+02 3.000e+01 3.800e+01 8.300e+01 4.330e+01 1.830e-01\n",
            "  3.300e+01]\n",
            " [1.000e+00 1.150e+02 7.000e+01 3.000e+01 9.600e+01 3.460e+01 5.290e-01\n",
            "  3.200e+01]\n",
            " [3.000e+00 1.260e+02 8.800e+01 4.100e+01 2.350e+02 3.930e+01 7.040e-01\n",
            "  2.700e+01]\n",
            " [8.000e+00 9.900e+01 8.400e+01 0.000e+00 0.000e+00 3.540e+01 3.880e-01\n",
            "  5.000e+01]\n",
            " [7.000e+00 1.960e+02 9.000e+01 0.000e+00 0.000e+00 3.980e+01 4.510e-01\n",
            "  4.100e+01]\n",
            " [9.000e+00 1.190e+02 8.000e+01 3.500e+01 0.000e+00 2.900e+01 2.630e-01\n",
            "  2.900e+01]\n",
            " [1.100e+01 1.430e+02 9.400e+01 3.300e+01 1.460e+02 3.660e+01 2.540e-01\n",
            "  5.100e+01]\n",
            " [1.000e+01 1.250e+02 7.000e+01 2.600e+01 1.150e+02 3.110e+01 2.050e-01\n",
            "  4.100e+01]\n",
            " [7.000e+00 1.470e+02 7.600e+01 0.000e+00 0.000e+00 3.940e+01 2.570e-01\n",
            "  4.300e+01]\n",
            " [1.000e+00 9.700e+01 6.600e+01 1.500e+01 1.400e+02 2.320e+01 4.870e-01\n",
            "  2.200e+01]\n",
            " [1.300e+01 1.450e+02 8.200e+01 1.900e+01 1.100e+02 2.220e+01 2.450e-01\n",
            "  5.700e+01]\n",
            " [5.000e+00 1.170e+02 9.200e+01 0.000e+00 0.000e+00 3.410e+01 3.370e-01\n",
            "  3.800e+01]\n",
            " [5.000e+00 1.090e+02 7.500e+01 2.600e+01 0.000e+00 3.600e+01 5.460e-01\n",
            "  6.000e+01]\n",
            " [3.000e+00 1.580e+02 7.600e+01 3.600e+01 2.450e+02 3.160e+01 8.510e-01\n",
            "  2.800e+01]\n",
            " [3.000e+00 8.800e+01 5.800e+01 1.100e+01 5.400e+01 2.480e+01 2.670e-01\n",
            "  2.200e+01]\n",
            " [6.000e+00 9.200e+01 9.200e+01 0.000e+00 0.000e+00 1.990e+01 1.880e-01\n",
            "  2.800e+01]\n",
            " [1.000e+01 1.220e+02 7.800e+01 3.100e+01 0.000e+00 2.760e+01 5.120e-01\n",
            "  4.500e+01]\n",
            " [4.000e+00 1.030e+02 6.000e+01 3.300e+01 1.920e+02 2.400e+01 9.660e-01\n",
            "  3.300e+01]\n",
            " [1.100e+01 1.380e+02 7.600e+01 0.000e+00 0.000e+00 3.320e+01 4.200e-01\n",
            "  3.500e+01]\n",
            " [9.000e+00 1.020e+02 7.600e+01 3.700e+01 0.000e+00 3.290e+01 6.650e-01\n",
            "  4.600e+01]\n",
            " [2.000e+00 9.000e+01 6.800e+01 4.200e+01 0.000e+00 3.820e+01 5.030e-01\n",
            "  2.700e+01]\n",
            " [4.000e+00 1.110e+02 7.200e+01 4.700e+01 2.070e+02 3.710e+01 1.390e+00\n",
            "  5.600e+01]\n",
            " [3.000e+00 1.800e+02 6.400e+01 2.500e+01 7.000e+01 3.400e+01 2.710e-01\n",
            "  2.600e+01]\n",
            " [7.000e+00 1.330e+02 8.400e+01 0.000e+00 0.000e+00 4.020e+01 6.960e-01\n",
            "  3.700e+01]\n",
            " [7.000e+00 1.060e+02 9.200e+01 1.800e+01 0.000e+00 2.270e+01 2.350e-01\n",
            "  4.800e+01]\n",
            " [9.000e+00 1.710e+02 1.100e+02 2.400e+01 2.400e+02 4.540e+01 7.210e-01\n",
            "  5.400e+01]]\n",
            "---------------------------------\n",
            "Atributos de Entrada\n",
            "---------------------------------\n",
            "[[6.000e+00 1.480e+02 7.200e+01 3.500e+01 0.000e+00 3.360e+01 6.270e-01\n",
            "  5.000e+01]\n",
            " [1.000e+00 8.500e+01 6.600e+01 2.900e+01 0.000e+00 2.660e+01 3.510e-01\n",
            "  3.100e+01]\n",
            " [8.000e+00 1.830e+02 6.400e+01 0.000e+00 0.000e+00 2.330e+01 6.720e-01\n",
            "  3.200e+01]\n",
            " [1.000e+00 8.900e+01 6.600e+01 2.300e+01 9.400e+01 2.810e+01 1.670e-01\n",
            "  2.100e+01]\n",
            " [0.000e+00 1.370e+02 4.000e+01 3.500e+01 1.680e+02 4.310e+01 2.288e+00\n",
            "  3.300e+01]\n",
            " [5.000e+00 1.160e+02 7.400e+01 0.000e+00 0.000e+00 2.560e+01 2.010e-01\n",
            "  3.000e+01]\n",
            " [3.000e+00 7.800e+01 5.000e+01 3.200e+01 8.800e+01 3.100e+01 2.480e-01\n",
            "  2.600e+01]\n",
            " [1.000e+01 1.150e+02 0.000e+00 0.000e+00 0.000e+00 3.530e+01 1.340e-01\n",
            "  2.900e+01]\n",
            " [2.000e+00 1.970e+02 7.000e+01 4.500e+01 5.430e+02 3.050e+01 1.580e-01\n",
            "  5.300e+01]\n",
            " [8.000e+00 1.250e+02 9.600e+01 0.000e+00 0.000e+00 0.000e+00 2.320e-01\n",
            "  5.400e+01]\n",
            " [4.000e+00 1.100e+02 9.200e+01 0.000e+00 0.000e+00 3.760e+01 1.910e-01\n",
            "  3.000e+01]\n",
            " [1.000e+01 1.680e+02 7.400e+01 0.000e+00 0.000e+00 3.800e+01 5.370e-01\n",
            "  3.400e+01]\n",
            " [1.000e+01 1.390e+02 8.000e+01 0.000e+00 0.000e+00 2.710e+01 1.441e+00\n",
            "  5.700e+01]\n",
            " [1.000e+00 1.890e+02 6.000e+01 2.300e+01 8.460e+02 3.010e+01 3.980e-01\n",
            "  5.900e+01]\n",
            " [5.000e+00 1.660e+02 7.200e+01 1.900e+01 1.750e+02 2.580e+01 5.870e-01\n",
            "  5.100e+01]\n",
            " [7.000e+00 1.000e+02 0.000e+00 0.000e+00 0.000e+00 3.000e+01 4.840e-01\n",
            "  3.200e+01]\n",
            " [0.000e+00 1.180e+02 8.400e+01 4.700e+01 2.300e+02 4.580e+01 5.510e-01\n",
            "  3.100e+01]\n",
            " [7.000e+00 1.070e+02 7.400e+01 0.000e+00 0.000e+00 2.960e+01 2.540e-01\n",
            "  3.100e+01]\n",
            " [1.000e+00 1.030e+02 3.000e+01 3.800e+01 8.300e+01 4.330e+01 1.830e-01\n",
            "  3.300e+01]\n",
            " [1.000e+00 1.150e+02 7.000e+01 3.000e+01 9.600e+01 3.460e+01 5.290e-01\n",
            "  3.200e+01]\n",
            " [3.000e+00 1.260e+02 8.800e+01 4.100e+01 2.350e+02 3.930e+01 7.040e-01\n",
            "  2.700e+01]\n",
            " [8.000e+00 9.900e+01 8.400e+01 0.000e+00 0.000e+00 3.540e+01 3.880e-01\n",
            "  5.000e+01]\n",
            " [7.000e+00 1.960e+02 9.000e+01 0.000e+00 0.000e+00 3.980e+01 4.510e-01\n",
            "  4.100e+01]\n",
            " [9.000e+00 1.190e+02 8.000e+01 3.500e+01 0.000e+00 2.900e+01 2.630e-01\n",
            "  2.900e+01]\n",
            " [1.100e+01 1.430e+02 9.400e+01 3.300e+01 1.460e+02 3.660e+01 2.540e-01\n",
            "  5.100e+01]\n",
            " [1.000e+01 1.250e+02 7.000e+01 2.600e+01 1.150e+02 3.110e+01 2.050e-01\n",
            "  4.100e+01]\n",
            " [7.000e+00 1.470e+02 7.600e+01 0.000e+00 0.000e+00 3.940e+01 2.570e-01\n",
            "  4.300e+01]\n",
            " [1.000e+00 9.700e+01 6.600e+01 1.500e+01 1.400e+02 2.320e+01 4.870e-01\n",
            "  2.200e+01]\n",
            " [1.300e+01 1.450e+02 8.200e+01 1.900e+01 1.100e+02 2.220e+01 2.450e-01\n",
            "  5.700e+01]\n",
            " [5.000e+00 1.170e+02 9.200e+01 0.000e+00 0.000e+00 3.410e+01 3.370e-01\n",
            "  3.800e+01]\n",
            " [5.000e+00 1.090e+02 7.500e+01 2.600e+01 0.000e+00 3.600e+01 5.460e-01\n",
            "  6.000e+01]\n",
            " [3.000e+00 1.580e+02 7.600e+01 3.600e+01 2.450e+02 3.160e+01 8.510e-01\n",
            "  2.800e+01]\n",
            " [3.000e+00 8.800e+01 5.800e+01 1.100e+01 5.400e+01 2.480e+01 2.670e-01\n",
            "  2.200e+01]\n",
            " [6.000e+00 9.200e+01 9.200e+01 0.000e+00 0.000e+00 1.990e+01 1.880e-01\n",
            "  2.800e+01]\n",
            " [1.000e+01 1.220e+02 7.800e+01 3.100e+01 0.000e+00 2.760e+01 5.120e-01\n",
            "  4.500e+01]\n",
            " [4.000e+00 1.030e+02 6.000e+01 3.300e+01 1.920e+02 2.400e+01 9.660e-01\n",
            "  3.300e+01]\n",
            " [1.100e+01 1.380e+02 7.600e+01 0.000e+00 0.000e+00 3.320e+01 4.200e-01\n",
            "  3.500e+01]\n",
            " [9.000e+00 1.020e+02 7.600e+01 3.700e+01 0.000e+00 3.290e+01 6.650e-01\n",
            "  4.600e+01]\n",
            " [2.000e+00 9.000e+01 6.800e+01 4.200e+01 0.000e+00 3.820e+01 5.030e-01\n",
            "  2.700e+01]\n",
            " [4.000e+00 1.110e+02 7.200e+01 4.700e+01 2.070e+02 3.710e+01 1.390e+00\n",
            "  5.600e+01]\n",
            " [3.000e+00 1.800e+02 6.400e+01 2.500e+01 7.000e+01 3.400e+01 2.710e-01\n",
            "  2.600e+01]\n",
            " [7.000e+00 1.330e+02 8.400e+01 0.000e+00 0.000e+00 4.020e+01 6.960e-01\n",
            "  3.700e+01]\n",
            " [7.000e+00 1.060e+02 9.200e+01 1.800e+01 0.000e+00 2.270e+01 2.350e-01\n",
            "  4.800e+01]\n",
            " [9.000e+00 1.710e+02 1.100e+02 2.400e+01 2.400e+02 4.540e+01 7.210e-01\n",
            "  5.400e+01]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np \n",
        "from sklearn import preprocessing\n",
        "\n",
        "# Binarizador de rótulo\n",
        "processo = preprocessing.MinMaxScaler()\n",
        "\n",
        "Gravidez = processo.fit_transform(np.array(base_Treinamento[:, 0]).reshape(-1,1))\n",
        "Glicose = processo.fit_transform(np.array(base_Treinamento[:, 1]).reshape(-1,1))\n",
        "PressaoArterial = processo.fit_transform(np.array(base_Treinamento[:, 2]).reshape(-1,1))\n",
        "EspessuraPele = processo.fit_transform(np.array(base_Treinamento[:, 3]).reshape(-1,1))\n",
        "Insulina = processo.fit_transform(np.array(base_Treinamento[:, 4]).reshape(-1,1))\n",
        "BMI = processo.fit_transform(np.array(base_Treinamento[:, 5]).reshape(-1,1))\n",
        "DiabetePedigree =processo.fit_transform(np.array(base_Treinamento[:, 6]).reshape(-1,1))\n",
        "Idade = processo.fit_transform(np.array(base_Treinamento[:, 7]).reshape(-1,1))\n",
        "\n",
        "atributos_norm = np.column_stack((Gravidez,Glicose,PressaoArterial,EspessuraPele,Insulina,BMI,DiabetePedigree,Idade))\n",
        "print(\"--------------------------------\")\n",
        "print(\"Atributos de Entrada - Numéricos\")\n",
        "print(\"--------------------------------\")\n",
        "print(atributos_norm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4NtTvsdKiofs",
        "outputId": "177082e7-d1ef-4d2f-deea-90261446e185"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------\n",
            "Atributos de Entrada - Numéricos\n",
            "--------------------------------\n",
            "[[0.35294118 0.74371859 0.59016393 ... 0.50074516 0.23441503 0.48333333]\n",
            " [0.05882353 0.42713568 0.54098361 ... 0.39642325 0.11656704 0.16666667]\n",
            " [0.47058824 0.91959799 0.52459016 ... 0.34724292 0.25362938 0.18333333]\n",
            " ...\n",
            " [0.29411765 0.6080402  0.59016393 ... 0.390462   0.07130658 0.15      ]\n",
            " [0.05882353 0.63316583 0.49180328 ... 0.4485842  0.11571307 0.43333333]\n",
            " [0.05882353 0.46733668 0.57377049 ... 0.45305514 0.10119556 0.03333333]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_Predicao = modelo.predict((atributos_norm))\n",
        "print(\"Classificações: \", base_Predicao)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ygzlvL0TjCoe",
        "outputId": "22ced456-14bf-471d-86f6-58fcdc346db2"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classificações:  [1. 0. 1. 0. 1. 0. 1. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1.\n",
            " 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0.\n",
            " 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0.\n",
            " 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0.\n",
            " 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0.\n",
            " 1. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0.\n",
            " 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0.\n",
            " 1. 1. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1.\n",
            " 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0.\n",
            " 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0.\n",
            " 1. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1.\n",
            " 0. 0. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0. 0.\n",
            " 1. 0. 1. 0. 0. 1. 0. 1. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0.\n",
            " 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1.\n",
            " 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0.\n",
            " 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 1. 1. 0. 1. 0. 1. 0. 1. 0.\n",
            " 1. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0.\n",
            " 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1.\n",
            " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
            " 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.\n",
            " 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
            " 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0.\n",
            " 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 1.\n",
            " 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0.\n",
            " 0. 0. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1.\n",
            " 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1.\n",
            " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1.\n",
            " 0. 0. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0.]\n"
          ]
        }
      ]
    }
  ]
}